{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import mpl_toolkits\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_property_list_sold(city, state, prop_type, limit=200):\n",
    "    \n",
    "  # url for api\n",
    "  url = \"https://realtor.p.rapidapi.com/properties/v2/list-sold\"\n",
    "\n",
    "  # enter parameters\n",
    "  querystring = {\n",
    "    \"sort\":\"sold_date\",\n",
    "    \"city\":city,\n",
    "    \"offset\":\"0\",\n",
    "    \"state_code\":state,\n",
    "    \"limit\":limit,\n",
    "    \"prop_type\":prop_type\n",
    "  }\n",
    "\n",
    "  headers = {\n",
    "    'x-rapidapi-host': \"realtor.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"95338ea407msh3cf14ebb0eb2e8dp107b98jsnbd45c26c0423\"\n",
    "  }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "  return response.json() # json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_sold_response(response_json):\n",
    "\n",
    "    \"\"\"\n",
    "    Process the list for sale API response.\n",
    "\n",
    "    Convert each listing to a dataframe, append to a list, and concatenate to one dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    @response_json [dictionary]: API response for list sold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    [dataframe] Dataframe of all list sold responses\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # empty dataframe\n",
    "    dataframe_list = []\n",
    "\n",
    "    # iterate through each sold listing\n",
    "    for l in response_json['properties']:\n",
    "\n",
    "        # convert each listing to dataframe\n",
    "        _temp_df = pd.DataFrame.from_dict(l, orient='index').T\n",
    "\n",
    "        # append to dataframe list for all listings\n",
    "        dataframe_list.append(_temp_df)\n",
    "\n",
    "    # concatenate all dataframes, for missing col values enter null value\n",
    "    return pd.concat(dataframe_list, axis=0, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key to access data\n",
    "city = \"Gainesville\"\n",
    "state = \"FL\"\n",
    "prop_type = \"single_family\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_list_sold_response = api_property_list_sold(city=city, \n",
    "                                                     state=state, \n",
    "                                                     prop_type=prop_type,\n",
    "                                                     limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_list_sold_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties_sold_raw = process_list_sold_response(response_json=property_list_sold_response)\n",
    "df_properties_sold_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataframe to CSV so that project data will stay consistent\n",
    "df_properties_sold_raw.to_csv(r'C:\\Users\\green\\OneDrive\\Documents\\DSC680\\Project1\\HomePricesGainesville071320.csv', \n",
    "                              index=False, sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\green\\OneDrive\\Documents\\DSC680\\Project1\\HomePricesGainesville071320.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns that are identifiers only\n",
    "df.drop(columns=['property_id', 'listing_id', 'prop_type', 'list_date', 'last_update', 'prop_status', 'address', 'mls', \n",
    "                 'client_display_flags', 'sold_history', 'office', 'agents', 'rdc_web_url', 'rdc_app_url', 'data_source_name', \n",
    "                 'page_no', 'rank', 'list_tracking', 'photos', 'price_reduced_date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'NaN' values with '0'\n",
    "df= df.replace(np.nan,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(dftotrim):\n",
    "    # Trim off size and unit strings \n",
    "           \n",
    "    dftotrim['lot_size'] = dftotrim['lot_size'].str.extract('(\\d+)')\n",
    "    dftotrim['building_size'] = dftotrim['building_size'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim(df)\n",
    "# Output dataframe to CSV so that project data can be reviewed\n",
    "df.to_csv(r'C:\\Users\\green\\OneDrive\\Documents\\DSC680\\Project1\\HomePricesGainesville071320trim.csv', \n",
    "                              index=False, sep=',',encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Univariate Statistics\n",
    "\n",
    "def unistats(df):\n",
    "    # Create some statistics\n",
    "    \n",
    "    output_df = pd.DataFrame(columns=['Count', 'Missing', 'Unique', 'Dtype', 'Mean', 'Mode', 'Min', '25%', 'Median', '75%', 'Max', 'Std', 'Skew', 'Kurt'])\n",
    "    \n",
    "    for col in df:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            output_df.loc[col] = [df[col].count(), df[col].isnull().sum(), df[col].nunique(), df[col].dtype, df[col].mean(), \n",
    "                                  df[col].mode().values[0], df[col].min(), df[col].quantile(.25), df[col].median(), \n",
    "                                  df[col].quantile(.75), df[col].max(), df[col].std(), df[col].skew(), df[col].kurt()]\n",
    "        else:\n",
    "            output_df.loc[col] = [df[col].count(), df[col].isnull().sum(), df[col].nunique(), df[col].dtype, '-', \n",
    "                                  df[col].mode().values[0], '-', '-', '-', '-', '-', '-', '-', '-']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unistats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# There are 3 entries where lot size is missing.  Remove those.\n",
    "df['lot_size'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['lot_size'], inplace=True)\n",
    "unistats(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change variable type from float or object to int\n",
    "df['garage'] = df['garage'].astype(int)\n",
    "df['baths_half'] = df['baths_half'].astype(int)\n",
    "df['lot_size'] = df['lot_size'].astype(int)\n",
    "unistats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivstats(df, label):\n",
    "    #Create empty DataFrame to store output\n",
    "    output_df = pd.DataFrame(columns = ['r', 'p-value'])\n",
    "    # r = Pearson Correlation\n",
    "    \n",
    "    for col in df: \n",
    "        if not col == label:      \n",
    "            r, p = stats.pearsonr(df[label], df[col])\n",
    "            output_df.loc[col] = [round(r, 3), round(p,5)]\n",
    "    return output_df.sort_values(by=['r'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivstats(df, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new construction feature\n",
    "df.drop(columns=['is_new_construction'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plots with histograms\n",
    "def scatter(df, label):\n",
    "    sns.set(color_codes = True)\n",
    "    for col in df:        \n",
    "        if not col == label:\n",
    "            sns.jointplot(df[col], df[label], kind = 'reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(df, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate outliers \n",
    "# lot_size has 2 points that should be removed\n",
    "# We can remove any lot_size entries above 200000\n",
    "df.drop(df[df.lot_size > 200000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get new stats\n",
    "bivstats(df, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw new scatter plots\n",
    "scatter(df, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate Statistics and Model Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform scaling and preprocessing\n",
    "def mlr_prepare(df):\n",
    "    df = df.select_dtypes(np.number)\n",
    "    df_minmax = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df), columns = df.columns)\n",
    "    return df_minmax\n",
    "\n",
    "df_minmax = mlr_prepare(df)\n",
    "df_minmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MLR (Multivariate Linear Regression)\n",
    "def mlr(df, label):\n",
    "    y = df[label]\n",
    "    X = df.drop(columns = [label]).assign(const = 1)\n",
    "    results = sm.OLS(y, X).fit()\n",
    "    return results\n",
    "\n",
    "results = mlr(df, 'price')\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fit stats and create a record entry for modeling results table\n",
    "def mlr_fit(results, actual, roundto=10):\n",
    "    #generate feature table that allows sorting coef labels based on t and p\n",
    "    df_features = mlr_feature_df(results)\n",
    "    residuals = np.array(actual) - np.array(results.fittedvalues)\n",
    "    rmse = np.sqrt(sum((residuals**2))/len(actual))\n",
    "    mae = np.mean(abs(np.array(actual) - np.array(results.fittedvalues)))\n",
    "    fit_stats = [round(results.rsquared, roundto), round(results.rsquared_adj, roundto),\n",
    "                round(results.rsquared - results.rsquared_adj, roundto), round(rmse, roundto), \n",
    "                round(mae, roundto), [df_features.index.values]]\n",
    "    return fit_stats\n",
    "\n",
    "fit_metrics_list = mlr_fit(results, df['price'])\n",
    "fit_metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DataFrame that allows us to sort features by t and p values\n",
    "def mlr_feature_df(results):\n",
    "    df_features = pd.DataFrame({'coef':results.params, 't':abs(results.tvalues), 'p':round(results.pvalues,6)})\n",
    "    df_features.drop(labels = ['const'], inplace = True)\n",
    "    df_features = df_features.sort_values(by = ['t', 'p'])\n",
    "    return df_features\n",
    "\n",
    "df_features = mlr_feature_df(results)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control mlr and mlr_fit by removing certain features\n",
    "def mlr_step(df, label, min = 2):\n",
    "    #create empty model results table\n",
    "    df_models = pd.DataFrame(columns = ['R2', 'R2a', 'diff', 'RMSE', 'MAE', 'features'])\n",
    "    #prepare data by generating dummies and scaling\n",
    "    df = mlr_prepare(df)\n",
    "    #run first model with all features\n",
    "    results = mlr(df, label)\n",
    "    #generate fit stats for model\n",
    "    df_models.loc[str(len(results.params))] = mlr_fit(results, df[label], 10)\n",
    "    #generate feature table that allows sorting coef labels based on t and p\n",
    "    df_features = mlr_feature_df(results)\n",
    "    #step through series of reduced models until minimum # of features left\n",
    "    while len(results.params) >= min:\n",
    "        df = df.drop(columns = [df_features.index[0]])  #drop least effective feature\n",
    "        results = mlr(df, label)                        #re-run next MLR\n",
    "        df_features = mlr_feature_df(results)           #re-generate the features summary table\n",
    "        df_models.loc[len(results.params)] = mlr_fit(results, df[label], 10)\n",
    "    #save full models table to a csv\n",
    "    df_models.to_csv('C:/Users/green/OneDrive/Documents/DSC680/Project1/' + label + '.csv')\n",
    "    #return a shortened version without feature list\n",
    "    df_models.drop(columns = ['features'], inplace = True)\n",
    "    return df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = mlr_step(df, 'price')\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "#\n",
    "# Looking at R2, it starts to decline more rapidly after the 8rd feature is removed.\n",
    "# By looking at our price.csv that was created, we can see that we can remove: \n",
    "# photo_count (# of photos in the listing)\n",
    "# baths_full (# of full bathrooms)\n",
    "# baths_half (# of half bathrooms)\n",
    "# baths (total # of bathrooms, half or full, in integers)\n",
    "# year-built (year in which the house was built)\n",
    "# beds (# of bedrooms)\n",
    "#\n",
    "# All of these features, once removed, hardly make a difference in R2, R2a, RMSE, or MAE.\n",
    "# \n",
    "# The remaining features in decreasing importance are:\n",
    "# building_size (square footage of house)\n",
    "# garage (size of garage by # of cars it can fit)\n",
    "#\n",
    "# This really surprises me that the garage size is the second most important feature!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets remove the extraneous features and get a MLR equation\n",
    "dfnew = df.drop(columns = ['photo_count', 'baths_full', 'baths_half', 'baths', 'year_built', 'beds', 'lot_size'])\n",
    "\n",
    "results = mlr(dfnew, 'price')\n",
    "fit_metrics_list = mlr_fit(results, df['price'])\n",
    "df_features = mlr_feature_df(results)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our formula to predict price of a house would be price = (32248.8 * garage) + (136.8 * building_size)\n",
    "# lets test with the 1st entry: price = (32248.8 * 2) + (136.8 * 2715) = 435909.6\n",
    "# Actual price is 415000, off by 5%.  Lets add 'beds' back and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnewer = df.drop(columns = ['photo_count', 'baths_full', 'baths_half', 'baths', 'year_built', 'lot_size'])\n",
    "\n",
    "results = mlr(dfnewer, 'price')\n",
    "fit_metrics_list = mlr_fit(results, df['price'])\n",
    "df_features = mlr_feature_df(results)\n",
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our formula to predict price of a house would be price = (31145.8 * garage) + (151.8 * building_size) - (20869.2 * beds)\n",
    "# lets test with the 1st entry: price = (31145.8 * 2) + (151.8 * 2715) - (20869.2 * 4) = 390951.8\n",
    "# Actual price is 415000, off by 6%.  It appears our original assessment might be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The price of a house in Gainesville, FL can be determined with ~95% accuracy with the following formula:\n",
    "# price = 137x + 32249y, where x is the building size in sqft, and y is the size of the garage in cars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
